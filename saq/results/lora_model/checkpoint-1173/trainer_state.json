{
  "best_metric": 0.43041032552719116,
  "best_model_checkpoint": "./lora_model/checkpoint-782",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1173,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1278772378516624,
      "grad_norm": 3.32869553565979,
      "learning_rate": 0.0001,
      "loss": 2.8121,
      "step": 50
    },
    {
      "epoch": 0.2557544757033248,
      "grad_norm": 1.8596652746200562,
      "learning_rate": 0.0002,
      "loss": 0.9046,
      "step": 100
    },
    {
      "epoch": 0.3836317135549872,
      "grad_norm": 1.729424238204956,
      "learning_rate": 0.00019068033550792172,
      "loss": 0.7077,
      "step": 150
    },
    {
      "epoch": 0.5115089514066496,
      "grad_norm": 1.590445637702942,
      "learning_rate": 0.00018136067101584343,
      "loss": 0.6271,
      "step": 200
    },
    {
      "epoch": 0.639386189258312,
      "grad_norm": 2.0338709354400635,
      "learning_rate": 0.00017204100652376515,
      "loss": 0.553,
      "step": 250
    },
    {
      "epoch": 0.7672634271099744,
      "grad_norm": 2.4628171920776367,
      "learning_rate": 0.00016272134203168688,
      "loss": 0.532,
      "step": 300
    },
    {
      "epoch": 0.8951406649616368,
      "grad_norm": 1.9999306201934814,
      "learning_rate": 0.0001534016775396086,
      "loss": 0.5041,
      "step": 350
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.4997464120388031,
      "eval_runtime": 22.5065,
      "eval_samples_per_second": 34.746,
      "eval_steps_per_second": 8.709,
      "step": 391
    },
    {
      "epoch": 1.0230179028132993,
      "grad_norm": 1.6059828996658325,
      "learning_rate": 0.0001440820130475303,
      "loss": 0.4295,
      "step": 400
    },
    {
      "epoch": 1.1508951406649617,
      "grad_norm": 1.2959227561950684,
      "learning_rate": 0.000134762348555452,
      "loss": 0.362,
      "step": 450
    },
    {
      "epoch": 1.278772378516624,
      "grad_norm": 1.9274232387542725,
      "learning_rate": 0.0001254426840633737,
      "loss": 0.3712,
      "step": 500
    },
    {
      "epoch": 1.4066496163682864,
      "grad_norm": 1.5476324558258057,
      "learning_rate": 0.00011612301957129543,
      "loss": 0.3387,
      "step": 550
    },
    {
      "epoch": 1.5345268542199488,
      "grad_norm": 1.5627316236495972,
      "learning_rate": 0.00010680335507921716,
      "loss": 0.3292,
      "step": 600
    },
    {
      "epoch": 1.6624040920716112,
      "grad_norm": 1.3005274534225464,
      "learning_rate": 9.748369058713887e-05,
      "loss": 0.3113,
      "step": 650
    },
    {
      "epoch": 1.7902813299232738,
      "grad_norm": 1.7664915323257446,
      "learning_rate": 8.816402609506058e-05,
      "loss": 0.3054,
      "step": 700
    },
    {
      "epoch": 1.918158567774936,
      "grad_norm": 2.4899089336395264,
      "learning_rate": 7.884436160298229e-05,
      "loss": 0.2884,
      "step": 750
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.43041032552719116,
      "eval_runtime": 22.4989,
      "eval_samples_per_second": 34.757,
      "eval_steps_per_second": 8.712,
      "step": 782
    },
    {
      "epoch": 2.0460358056265986,
      "grad_norm": 1.6335046291351318,
      "learning_rate": 6.952469711090402e-05,
      "loss": 0.2703,
      "step": 800
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 1.88382089138031,
      "learning_rate": 6.020503261882573e-05,
      "loss": 0.2522,
      "step": 850
    },
    {
      "epoch": 2.3017902813299234,
      "grad_norm": 1.193421483039856,
      "learning_rate": 5.0885368126747433e-05,
      "loss": 0.2459,
      "step": 900
    },
    {
      "epoch": 2.4296675191815855,
      "grad_norm": 1.4339871406555176,
      "learning_rate": 4.156570363466916e-05,
      "loss": 0.2434,
      "step": 950
    },
    {
      "epoch": 2.557544757033248,
      "grad_norm": 1.5589661598205566,
      "learning_rate": 3.2246039142590864e-05,
      "loss": 0.2439,
      "step": 1000
    },
    {
      "epoch": 2.6854219948849103,
      "grad_norm": 1.4311758279800415,
      "learning_rate": 2.2926374650512583e-05,
      "loss": 0.2366,
      "step": 1050
    },
    {
      "epoch": 2.813299232736573,
      "grad_norm": 1.0883632898330688,
      "learning_rate": 1.3606710158434296e-05,
      "loss": 0.2352,
      "step": 1100
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 1.8292244672775269,
      "learning_rate": 4.287045666356011e-06,
      "loss": 0.2315,
      "step": 1150
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.44161877036094666,
      "eval_runtime": 22.517,
      "eval_samples_per_second": 34.729,
      "eval_steps_per_second": 8.705,
      "step": 1173
    }
  ],
  "logging_steps": 50,
  "max_steps": 1173,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.164765803801477e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
